{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Wifi Positioning with RSSI Fingerprints\n",
    "You will get a dataset that was gathered by the Minodes team to enable wifi positioning. In this store we installed 145 of our sensors, also called **nodes**. \n",
    "\n",
    "As you walk through the store your phone searches for available wifi networks, by sending probe requests (see 802.11 standard). A part of this probe request is the received signal strength indication (**RSSI**), which has a range between 0db (very strong signal) and -100db (very weak signal). Depending on the distance of your phone to a sensor, the **RSSI** has a different value. In an ideal case one probe request would be perceived by all nodes of the store with different signal strength. In our data processing we collect all this probe requests and aggregate them, so that we have all **RSSI** values for all nodes of one probe request available:\n",
    "\n",
    "A data set might look like this:\n",
    "\n",
    "\n",
    "|  ID             | RSSI value node 1 | RSSI value node 2  | .... | RSSI value node n  | fr_zone_id |\n",
    "| -------------   |-------------      | -----              | -----| -------------------| ------- |\n",
    "| 1               |-70                | -70                | .... |  -70               | 1       |\n",
    "| 2               |-55                | -60                | .... |  -45               | 2       |\n",
    "| 2               |-60                | -60                | .... |  -45               | 2       |\n",
    "| ...             |.......            | ....               | .... | ....               | ..      |\n",
    "\n",
    "Each line of this the table is called a fingerprint, which gives us an indication about the potential location of a person.\n",
    "\n",
    "To locate a person within the store, we separate the store into zones representing compartments of a store. For each of this **zones** we collect reference data, which is stored in the file *training_set.csv* of this exercise.\n",
    "\n",
    "The goal of this task is to use machine learning techniques to predict the correct zones, based on **RSSI** fingerprints. At the end of this task you need to predict the zones of unkown **RSSI** fingerprints stored in the file *test_without_target.csv*. \n",
    "\n",
    "Since we at Minodes love to code, we have done some preparation work, so you can focus on the machine learning.\n",
    "\n",
    "In case you have any questions please contact **alexander.mueller@minodes.com**\n",
    "\n",
    "## Remarks\n",
    "\n",
    "* Please use python 3.x\n",
    "* I suggest using an anaconda python distribution https://www.continuum.io/downloads\n",
    "* The code is tested in python 3.4\n",
    "* Please use pre-existing libraries\n",
    "\n",
    "## Requirements\n",
    "The current versions of:\n",
    "* pandas \n",
    "* numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some imports and a preprocessing routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import linear_model,svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def preprocess_x_values(x_raw_values):\n",
    "    \"\"\"\n",
    "    A simple preprocessing routine returning a feature vector for the specific fingerprint. \n",
    "    \"\"\"\n",
    "\n",
    "    v = DictVectorizer(sparse=False)\n",
    "    \n",
    "    return v.fit_transform(x_raw_values)\n",
    "\n",
    "def compute_accuracy(Y,predY):\n",
    "    \n",
    "    accuracy = np.sum(Y==predY)/predY.shape[0] # Compute accuracy\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('training_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load training data\n",
    "\n",
    "# Parse dictionary of features\n",
    "training_set['values'] =training_set['values'].apply(lambda x:  ast.literal_eval(x))\n",
    "\n",
    "# preparing x and y sets \n",
    "# x are the features of the set\n",
    "# y is the class to be predicted\n",
    "x_raw = training_set['values']\n",
    "y = training_set['fr_zone_id']\n",
    "\n",
    "# preprocess the node dictionary to get feature vectors\n",
    "x_features= preprocess_x_values(x_raw)\n",
    "\n",
    "# Add column of 1's as additional feature to the dataset\n",
    "ones = np.ones((x_features.shape[0],1))\n",
    "x_features = np.concatenate((x_features,ones),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Think about how you validate your model (based on accuracy), what classifier you want to use and how in the end you want to scorce the test set.\n",
    "\n",
    "You need to add only a couple of lines of code to have a basic solution. Do this first and then iterate on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#  please start here\n",
    "\n",
    "# Uncomment a model you wish to train\n",
    "\n",
    "# Fit a linear regression model\n",
    "#model = linear_model.LinearRegression()\n",
    "#model.fit(x_features,y)\n",
    "\n",
    "# Fit a linear regression model with L2 regularizer\n",
    "#model = linear_model.Ridge()\n",
    "#model.fit(x_features,y)\n",
    "\n",
    "# Fit a logistic regression model\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(x_features,y.values)\n",
    "\n",
    "# Fit a SVM model\n",
    "#model = svm.SVC()\n",
    "#model.fit(x_features,y)\n",
    "\n",
    "# Use kNN algorithm\n",
    "#k = 10 # change hyperparameter k here\n",
    "#model = KNeighborsClassifier(n_neighbors=k)\n",
    "#model.fit(x_features,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Computing accuracy on training data\n",
    "predY_train = model.predict(x_features)\n",
    "predY_train = np.rint(predY_train) # Round off predictions to nearest integer, useful for linear/ridge regression\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy_train = compute_accuracy(y,predY_train) \n",
    "print(accuracy_train)\n",
    "\n",
    "# Compute confusion matrix\n",
    "confusion_matrix(y,predY_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and unkown dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('test_without_target.csv',index_col='id')\n",
    "test_set['values'] = test_set['values'].apply(lambda x:  ast.literal_eval(x))\n",
    "x_test = preprocess_x_values(test_set['values'])\n",
    "\n",
    "# Add column of 1's as additional feature to the dataset\n",
    "ones = np.ones((x_test.shape[0],1))\n",
    "x_test = np.concatenate((x_test,ones),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction on test data\n",
    "predY_test = model.predict(x_test)\n",
    "predY_test = np.rint(predY_test) # Round off predictions to nearest integer, useful for linear/ridge regression\n",
    "\n",
    "# Compute accuracy on test data (Here y_test are the ground truth labels)\n",
    "accuracy_test = compute_accuracy(y_test,predY_test)\n",
    "print(accuracy_test)\n",
    "\n",
    "# Compute confusion matrix (Here y_test are the ground truth labels)\n",
    "confusion_matrix(y_test,predY_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit your solution\n",
    "\n",
    "Please zip the complete folder with your solution and send it back to **alexander.mueller@minodes.com**. We will review it as soon as possible and will come back to you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
